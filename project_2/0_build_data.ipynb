{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://www.kaggle.com/c/favorita-grocery-sales-forecasting/overview\n",
    "* https://www.kaggle.com/shixw125/1st-place-lgb-model-public-0-506-private-0-511\n",
    "* https://www.kaggle.com/c/favorita-grocery-sales-forecasting/discussion/47582"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "import pathlib\n",
    "import gc\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import feather\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_PATH = pathlib.Path('/Users/palermopenano/personal/sm-202011/project_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(590381, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load full dataset\n",
    "# df_train = pd.read_csv(\n",
    "#     MAIN_PATH / 'data/train.csv',\n",
    "#     usecols=[1,2,3,4,5],\n",
    "#     dtype={'onpromotion': bool},\n",
    "#     converters={'unit_sales': lambda u: np.log1p(float(u)) if float(u) > 0 else 0},\n",
    "#     parse_dates=[\"date\"],\n",
    "#     skiprows=range(1, 66458909))\n",
    "\n",
    "# # Generate subsample of full data\n",
    "# df_train.sample(frac=.01).to_csv(MAIN_PATH / 'data/train_sample.csv')\n",
    "\n",
    "# Load small dataset for building pipeline\n",
    "df_train = pd.read_csv(\n",
    "    MAIN_PATH / 'data/train_sample.csv',\n",
    "    usecols=[1, 2, 3, 4, 5],\n",
    "    dtype={'onpromotion': bool},\n",
    "    converters={'unit_sales': lambda u: np.log1p(float(u)) if float(u) > 0 else 0},\n",
    "    parse_dates=[\"date\"]\n",
    ")\n",
    "\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3370464, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\n",
    "    MAIN_PATH / 'data/test.csv',\n",
    "    usecols=[0, 1, 2, 3, 4],\n",
    "    dtype={'onpromotion': bool},\n",
    "    parse_dates=[\"date\"]).set_index(['store_nbr', 'item_nbr', 'date'])\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4100, 3), (54, 4))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = pd.read_csv(\n",
    "    MAIN_PATH / \"data/items.csv\",\n",
    ").set_index(\"item_nbr\")\n",
    "\n",
    "stores = pd.read_csv(\n",
    "    MAIN_PATH / \"data/stores.csv\",\n",
    ").set_index(\"store_nbr\")\n",
    "\n",
    "items.shape, stores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(238021, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017 = df_train.loc[df_train.date >= pd.datetime(2017, 1, 1)]\n",
    "del df_train\n",
    "df_2017.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label encode categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "items['family'] = le.fit_transform(items['family'].values)\n",
    "stores['city'] = le.fit_transform(stores['city'].values)\n",
    "stores['state'] = le.fit_transform(stores['state'].values)\n",
    "stores['type'] = le.fit_transform(stores['type'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean promo variable\n",
    "\n",
    "Promo variable (bool) by store and item over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "promo_2017_train = (\n",
    "    df_2017.\n",
    "    set_index(['store_nbr', 'item_nbr', 'date'])[['onpromotion']].\n",
    "    unstack(level=-1).\n",
    "    fillna(False)\n",
    ")\n",
    "promo_2017_train.columns = promo_2017_train.columns.get_level_values(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "promo_2017_test = df_test[[\"onpromotion\"]].unstack(level=-1).fillna(False)\n",
    "promo_2017_test.columns = promo_2017_test.columns.get_level_values(1)\n",
    "promo_2017_test = promo_2017_test.reindex(promo_2017_train.index).fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>2017-01-01</th>\n",
       "      <th>2017-01-02</th>\n",
       "      <th>2017-01-03</th>\n",
       "      <th>2017-01-04</th>\n",
       "      <th>2017-01-05</th>\n",
       "      <th>2017-01-06</th>\n",
       "      <th>2017-01-07</th>\n",
       "      <th>2017-01-08</th>\n",
       "      <th>2017-01-09</th>\n",
       "      <th>2017-01-10</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-08-22</th>\n",
       "      <th>2017-08-23</th>\n",
       "      <th>2017-08-24</th>\n",
       "      <th>2017-08-25</th>\n",
       "      <th>2017-08-26</th>\n",
       "      <th>2017-08-27</th>\n",
       "      <th>2017-08-28</th>\n",
       "      <th>2017-08-29</th>\n",
       "      <th>2017-08-30</th>\n",
       "      <th>2017-08-31</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>96995</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105575</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105577</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">54</th>\n",
       "      <th>2088922</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089339</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2101795</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103250</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2110456</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115596 rows × 243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "date                2017-01-01  2017-01-02  2017-01-03  2017-01-04  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995          False       False       False       False   \n",
       "          103520         False       False       False       False   \n",
       "          103665         False       False       False       False   \n",
       "          105575         False       False       False       False   \n",
       "          105577         False       False       False       False   \n",
       "...                        ...         ...         ...         ...   \n",
       "54        2088922        False       False       False       False   \n",
       "          2089339        False       False       False       False   \n",
       "          2101795        False       False       False       False   \n",
       "          2103250        False       False       False       False   \n",
       "          2110456        False       False       False       False   \n",
       "\n",
       "date                2017-01-05  2017-01-06  2017-01-07  2017-01-08  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995          False       False       False       False   \n",
       "          103520         False       False       False       False   \n",
       "          103665         False       False       False       False   \n",
       "          105575         False       False       False       False   \n",
       "          105577         False       False       False       False   \n",
       "...                        ...         ...         ...         ...   \n",
       "54        2088922        False       False       False       False   \n",
       "          2089339        False       False       False       False   \n",
       "          2101795        False       False       False       False   \n",
       "          2103250        False       False       False       False   \n",
       "          2110456        False       False       False       False   \n",
       "\n",
       "date                2017-01-09  2017-01-10  ...  2017-08-22  2017-08-23  \\\n",
       "store_nbr item_nbr                          ...                           \n",
       "1         96995          False       False  ...       False       False   \n",
       "          103520         False       False  ...       False       False   \n",
       "          103665         False       False  ...       False       False   \n",
       "          105575         False       False  ...       False       False   \n",
       "          105577         False       False  ...       False        True   \n",
       "...                        ...         ...  ...         ...         ...   \n",
       "54        2088922        False       False  ...       False       False   \n",
       "          2089339        False       False  ...       False       False   \n",
       "          2101795        False       False  ...        True       False   \n",
       "          2103250        False       False  ...       False       False   \n",
       "          2110456        False       False  ...       False       False   \n",
       "\n",
       "date                2017-08-24  2017-08-25  2017-08-26  2017-08-27  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995          False       False       False       False   \n",
       "          103520         False       False       False       False   \n",
       "          103665         False       False       False       False   \n",
       "          105575          True        True        True        True   \n",
       "          105577          True        True        True        True   \n",
       "...                        ...         ...         ...         ...   \n",
       "54        2088922        False       False       False       False   \n",
       "          2089339        False       False       False       False   \n",
       "          2101795        False       False       False       False   \n",
       "          2103250        False       False       False       False   \n",
       "          2110456        False       False       False        True   \n",
       "\n",
       "date                2017-08-28  2017-08-29  2017-08-30  2017-08-31  \n",
       "store_nbr item_nbr                                                  \n",
       "1         96995          False       False       False       False  \n",
       "          103520         False       False       False       False  \n",
       "          103665         False       False       False       False  \n",
       "          105575          True        True        True        True  \n",
       "          105577          True       False        True        True  \n",
       "...                        ...         ...         ...         ...  \n",
       "54        2088922        False       False       False       False  \n",
       "          2089339        False       False       False       False  \n",
       "          2101795        False        True       False       False  \n",
       "          2103250        False       False       False       False  \n",
       "          2110456        False       False       False       False  \n",
       "\n",
       "[115596 rows x 243 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ??? Why is the train sample columns item ids but dates for the test sample?\n",
    "promo_2017 = pd.concat([promo_2017_train, promo_2017_test], axis=1)\n",
    "del promo_2017_test, promo_2017_train\n",
    "promo_2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sales by store, item and date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert df to long format with dates along columns and\n",
    "# store by item along as row axis\n",
    "# sales by store, item, and date\n",
    "df_2017 = (\n",
    "    df_2017.set_index([\"store_nbr\", \"item_nbr\", \"date\"])[[\"unit_sales\"]].\n",
    "    unstack(level=-1).\n",
    "    fillna(0)\n",
    ")\n",
    "df_2017.columns = df_2017.columns.get_level_values(1)\n",
    "\n",
    "# Set index for items and stores data to be the same as df_2017\n",
    "items = items.reindex(df_2017.index.get_level_values(1))\n",
    "stores = stores.reindex(df_2017.index.get_level_values(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item sales and num promotion per item over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total sales per item across all stores over time\n",
    "df_2017_item = df_2017.groupby('item_nbr')[df_2017.columns].sum()  \n",
    "\n",
    "# Number of promo per item over time\n",
    "promo_2017_item = promo_2017.groupby('item_nbr')[promo_2017.columns].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total sales per class and store over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total sales by item class and store over time\n",
    "df_2017_store_class = df_2017.reset_index()\n",
    "df_2017_store_class['class'] = items['class'].values\n",
    "df_2017_store_class_index = df_2017_store_class[['class', 'store_nbr']]\n",
    "df_2017_store_class = df_2017_store_class.groupby(['class', 'store_nbr'])[df_2017.columns].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total promo per class and store over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017_promo_store_class = promo_2017.reset_index()\n",
    "df_2017_promo_store_class['class'] = items['class'].values\n",
    "df_2017_promo_store_class_index = df_2017_promo_store_class[['class', 'store_nbr']]\n",
    "df_2017_promo_store_class = df_2017_promo_store_class.groupby(['class', 'store_nbr'])[promo_2017.columns].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prep functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timespan(df, dt, minus, periods, freq='D'):\n",
    "    '''Get subset of data based on date interval starting from (dt-minus)\n",
    "    and going forward `periods` number of periods.\n",
    "    \n",
    "    df is a dataframe in wide format with dates along the column\n",
    "    \n",
    "    >>> How pd.date_range works <<<\n",
    "    Example:\n",
    "    dt = 2017-6-14\n",
    "    minus = 1\n",
    "    from_date = dt - timedelta(days=minus)\n",
    "    periods = 3\n",
    "    pd.date_range(from_date, periods, freq='D') ==> DatetimeIndex(2017-6-13, 2017-6-14, 2017-6-15])\n",
    "    '''\n",
    "    from_date = dt - timedelta(days=minus)\n",
    "    \n",
    "    # Generate time periods from_date to P periods into the future (daily)\n",
    "    date_interval = pd.date_range(from_date, periods=periods, freq=freq)\n",
    "    return df[date_interval]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(df, t2017, is_train=True, name_prefix=None, num_days_preds=16):\n",
    "    '''Builds a dataframe containing statistical features at the store / item level\n",
    "    \n",
    "    Statistical features include mean, median, min, max, std for various historical date\n",
    "    periods (last 3, 7, 14, 30 etc. days) starting from reference period t2017\n",
    "    '''\n",
    "    X = {}\n",
    "\n",
    "#     for i in [2, 4]:\n",
    "    for i in [3, 7, 14, 30, 60, 140]:\n",
    "        tmp = get_timespan(df, t2017, minus=i, periods=i)\n",
    "        X['diff_%s_mean' % i] = tmp.diff(axis=1).mean(axis=1).values\n",
    "        X['mean_%s_decay' % i] = (tmp * np.power(0.9, np.arange(i)[::-1])).sum(axis=1).values\n",
    "        X['mean_%s' % i] = tmp.mean(axis=1).values\n",
    "        X['median_%s' % i] = tmp.median(axis=1).values\n",
    "        X['min_%s' % i] = tmp.min(axis=1).values\n",
    "        X['max_%s' % i] = tmp.max(axis=1).values\n",
    "        X['std_%s' % i] = tmp.std(axis=1).values\n",
    "\n",
    "    X = pd.DataFrame(X)\n",
    "\n",
    "    if is_train:\n",
    "        # Predict the next 16 periods from t2017\n",
    "        y_date_range = pd.date_range(t2017, periods=num_days_preds)\n",
    "        y = df[y_date_range].values\n",
    "        return X, y\n",
    "    if name_prefix is not None:\n",
    "        X.columns = ['%s_%s' % (name_prefix, c) for c in X.columns]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset...\n",
      "------------------------------\n",
      "days: 0\n",
      "from: 2017-06-14 | DatetimeIndex(['2017-06-14', '2017-06-15', '2017-06-16', '2017-06-17',\n",
      "               '2017-06-18', '2017-06-19', '2017-06-20', '2017-06-21',\n",
      "               '2017-06-22', '2017-06-23', '2017-06-24', '2017-06-25',\n",
      "               '2017-06-26', '2017-06-27', '2017-06-28', '2017-06-29'],\n",
      "              dtype='datetime64[ns]', freq='D')\n",
      "------------------------------\n",
      "days: 1\n",
      "from: 2017-06-21 | DatetimeIndex(['2017-06-21', '2017-06-22', '2017-06-23', '2017-06-24',\n",
      "               '2017-06-25', '2017-06-26', '2017-06-27', '2017-06-28',\n",
      "               '2017-06-29', '2017-06-30', '2017-07-01', '2017-07-02',\n",
      "               '2017-07-03', '2017-07-04', '2017-07-05', '2017-07-06'],\n",
      "              dtype='datetime64[ns]', freq='D')\n",
      "------------------------------\n",
      "days: 2\n",
      "from: 2017-06-28 | DatetimeIndex(['2017-06-28', '2017-06-29', '2017-06-30', '2017-07-01',\n",
      "               '2017-07-02', '2017-07-03', '2017-07-04', '2017-07-05',\n",
      "               '2017-07-06', '2017-07-07', '2017-07-08', '2017-07-09',\n",
      "               '2017-07-10', '2017-07-11', '2017-07-12', '2017-07-13'],\n",
      "              dtype='datetime64[ns]', freq='D')\n",
      "------------------------------\n",
      "days: 3\n",
      "from: 2017-07-05 | DatetimeIndex(['2017-07-05', '2017-07-06', '2017-07-07', '2017-07-08',\n",
      "               '2017-07-09', '2017-07-10', '2017-07-11', '2017-07-12',\n",
      "               '2017-07-13', '2017-07-14', '2017-07-15', '2017-07-16',\n",
      "               '2017-07-17', '2017-07-18', '2017-07-19', '2017-07-20'],\n",
      "              dtype='datetime64[ns]', freq='D')\n",
      "------------------------------\n",
      "days: 4\n",
      "from: 2017-07-12 | DatetimeIndex(['2017-07-12', '2017-07-13', '2017-07-14', '2017-07-15',\n",
      "               '2017-07-16', '2017-07-17', '2017-07-18', '2017-07-19',\n",
      "               '2017-07-20', '2017-07-21', '2017-07-22', '2017-07-23',\n",
      "               '2017-07-24', '2017-07-25', '2017-07-26', '2017-07-27'],\n",
      "              dtype='datetime64[ns]', freq='D')\n",
      "------------------------------\n",
      "days: 5\n",
      "from: 2017-07-19 | DatetimeIndex(['2017-07-19', '2017-07-20', '2017-07-21', '2017-07-22',\n",
      "               '2017-07-23', '2017-07-24', '2017-07-25', '2017-07-26',\n",
      "               '2017-07-27', '2017-07-28', '2017-07-29', '2017-07-30',\n",
      "               '2017-07-31', '2017-08-01', '2017-08-02', '2017-08-03'],\n",
      "              dtype='datetime64[ns]', freq='D')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diff_3_mean</th>\n",
       "      <th>mean_3_decay</th>\n",
       "      <th>mean_3</th>\n",
       "      <th>median_3</th>\n",
       "      <th>min_3</th>\n",
       "      <th>max_3</th>\n",
       "      <th>std_3</th>\n",
       "      <th>diff_7_mean</th>\n",
       "      <th>mean_7_decay</th>\n",
       "      <th>mean_7</th>\n",
       "      <th>...</th>\n",
       "      <th>std_140</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>class</th>\n",
       "      <th>perishable</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044505</td>\n",
       "      <td>96995</td>\n",
       "      <td>12</td>\n",
       "      <td>1093</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044505</td>\n",
       "      <td>103520</td>\n",
       "      <td>12</td>\n",
       "      <td>1028</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125510</td>\n",
       "      <td>103665</td>\n",
       "      <td>5</td>\n",
       "      <td>2712</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>105575</td>\n",
       "      <td>12</td>\n",
       "      <td>1045</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088280</td>\n",
       "      <td>105577</td>\n",
       "      <td>12</td>\n",
       "      <td>1045</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   diff_3_mean  mean_3_decay  mean_3  median_3  min_3  max_3  std_3  \\\n",
       "0          0.0           0.0     0.0       0.0    0.0    0.0    0.0   \n",
       "1          0.0           0.0     0.0       0.0    0.0    0.0    0.0   \n",
       "2          0.0           0.0     0.0       0.0    0.0    0.0    0.0   \n",
       "3          0.0           0.0     0.0       0.0    0.0    0.0    0.0   \n",
       "4          0.0           0.0     0.0       0.0    0.0    0.0    0.0   \n",
       "\n",
       "   diff_7_mean  mean_7_decay  mean_7  ...   std_140  item_nbr  family  class  \\\n",
       "0          0.0           0.0     0.0  ...  0.044505     96995      12   1093   \n",
       "1          0.0           0.0     0.0  ...  0.044505    103520      12   1028   \n",
       "2          0.0           0.0     0.0  ...  0.125510    103665       5   2712   \n",
       "3          0.0           0.0     0.0  ...  0.000000    105575      12   1045   \n",
       "4          0.0           0.0     0.0  ...  0.088280    105577      12   1045   \n",
       "\n",
       "   perishable  store_nbr  city  state  type  cluster  \n",
       "0           0          1    18     12     3       13  \n",
       "1           0          1    18     12     3       13  \n",
       "2           1          1    18     12     3       13  \n",
       "3           0          1    18     12     3       13  \n",
       "4           0          1    18     12     3       13  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Preparing dataset...\")\n",
    "\n",
    "t2017 = date(2017, 6, 14)  # last day to use for training\n",
    "num_days_preds = 16        # number of days into the future to predict (y values)\n",
    "\n",
    "num_days = 6\n",
    "# num_days = 1\n",
    "\n",
    "X_l, y_l = [], []\n",
    "\n",
    "\n",
    "# The for loop will take generate data along rows for different points in time\n",
    "# If we are calculating the 2-day mean for a given store/item, for example, \n",
    "# the for loop will calculate the 2-day mean from the starting date to last 2 days,\n",
    "# then in the next iteration, the 2-day mean from 7 days ago to the last 2 days from that date\n",
    "# In effect, each store/item combination will have num_days number of rows and the entire\n",
    "# dataset will be duplicated according to num_days\n",
    "for i in range(num_days):\n",
    "    print(\"------------------------------\")\n",
    "    print(f\"days: {i}\")\n",
    "    \n",
    "    delta = timedelta(days=7 * i)\n",
    "    \n",
    "    from_date = t2017 + delta\n",
    "    y_preds_range = pd.date_range(from_date, periods=num_days_preds)\n",
    "    print(f\"from: {from_date} | {y_preds_range}\")\n",
    "    \n",
    "    # Store by item level features (sales and promo)\n",
    "    X_tmp, y_tmp = prepare_dataset(df_2017, from_date)\n",
    "\n",
    "    X_tmp = pd.concat([X_tmp,  \n",
    "                       items.reset_index(), \n",
    "                       stores.reset_index()], \n",
    "                      axis=1)\n",
    "    \n",
    "    X_l.append(X_tmp)\n",
    "    y_l.append(y_tmp)\n",
    "\n",
    "# Concatenate along rows\n",
    "X_train = pd.concat(X_l, axis=0)\n",
    "y_train = np.concatenate(y_l, axis=0)\n",
    "\n",
    "del X_l, y_l\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create validation set\n",
    "val2017 = date(2017, 7, 26)\n",
    "X_val, y_val = prepare_dataset(df_2017, val2017)\n",
    "X_val = pd.concat([X_val, \n",
    "                   items.reset_index(), \n",
    "                   stores.reset_index()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test set\n",
    "test2017 = date(2017, 8, 16)\n",
    "X_test = prepare_dataset(df_2017, test2017, is_train=False)\n",
    "\n",
    "X_test = pd.concat([X_test, \n",
    "                    items.reset_index(), \n",
    "                    stores.reset_index()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del X_test2, X_val2, df_2017_item, promo_2017_item, df_2017_store_class, df_2017_promo_store_class, df_2017_store_class_index\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'num_leaves': 80,\n",
    "    'objective': 'regression',\n",
    "    'min_data_in_leaf': 200,\n",
    "    'learning_rate': 0.02,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.7,\n",
    "    'bagging_freq': 1,\n",
    "    'metric': 'l2',\n",
    "    'num_threads': 16\n",
    "}\n",
    "\n",
    "MAX_ROUNDS = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Step 1\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/palermopenano/miniconda3/envs/sm/lib/python3.7/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.00833986\tvalid_1's l2: 0.00853434\n",
      "[100]\ttraining's l2: 0.00830314\tvalid_1's l2: 0.00853559\n",
      "[150]\ttraining's l2: 0.00827232\tvalid_1's l2: 0.00853798\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's l2: 0.00832636\tvalid_1's l2: 0.00853416\n",
      "item_nbr: 89.95\n",
      "max_140: 74.80\n",
      "class: 67.91\n",
      "mean_140_decay: 52.22\n",
      "store_nbr: 42.57\n",
      "std_140: 33.95\n",
      "cluster: 27.92\n",
      "mean_140: 27.82\n",
      "family: 24.63\n",
      "city: 19.35\n",
      "max_60: 16.82\n",
      "mean_60_decay: 15.92\n",
      "state: 14.72\n",
      "std_60: 14.00\n",
      "max_30: 12.42\n",
      "mean_60: 11.77\n",
      "type: 11.12\n",
      "mean_30_decay: 7.23\n",
      "mean_30: 7.18\n",
      "mean_14_decay: 6.99\n",
      "perishable: 5.05\n",
      "std_30: 4.85\n",
      "max_14: 4.16\n",
      "mean_14: 3.28\n",
      "diff_7_mean: 2.60\n",
      "diff_3_mean: 2.39\n",
      "mean_7_decay: 2.25\n",
      "max_7: 2.11\n",
      "std_14: 1.52\n",
      "diff_60_mean: 1.24\n",
      "mean_3_decay: 1.22\n",
      "mean_7: 1.01\n",
      "diff_30_mean: 0.83\n",
      "std_3: 0.48\n",
      "diff_14_mean: 0.35\n",
      "mean_3: 0.23\n",
      "diff_140_mean: 0.21\n",
      "std_7: 0.19\n",
      "max_3: 0.19\n",
      "median_3: 0.00\n",
      "min_3: 0.00\n",
      "median_7: 0.00\n",
      "min_7: 0.00\n",
      "median_14: 0.00\n",
      "min_14: 0.00\n",
      "median_30: 0.00\n",
      "min_30: 0.00\n",
      "median_60: 0.00\n",
      "min_60: 0.00\n",
      "median_140: 0.00\n",
      "min_140: 0.00\n",
      "==================================================\n",
      "Step 2\n",
      "==================================================\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.00759508\tvalid_1's l2: 0.00754374\n",
      "[100]\ttraining's l2: 0.00756243\tvalid_1's l2: 0.00754535\n",
      "[150]\ttraining's l2: 0.00753532\tvalid_1's l2: 0.00754835\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's l2: 0.00759928\tvalid_1's l2: 0.00754355\n",
      "max_140: 48.95\n",
      "item_nbr: 46.55\n",
      "class: 32.95\n",
      "mean_140_decay: 27.46\n",
      "std_140: 23.35\n",
      "mean_140: 22.94\n",
      "store_nbr: 22.23\n",
      "cluster: 18.80\n",
      "max_60: 12.70\n",
      "family: 12.15\n",
      "max_30: 10.65\n",
      "mean_60_decay: 10.10\n",
      "city: 9.28\n",
      "mean_60: 8.66\n",
      "std_60: 8.40\n",
      "state: 7.97\n",
      "std_30: 6.45\n",
      "mean_14_decay: 5.89\n",
      "type: 5.33\n",
      "mean_30_decay: 4.52\n",
      "mean_3_decay: 4.46\n",
      "mean_30: 3.86\n",
      "max_7: 2.88\n",
      "perishable: 2.35\n",
      "diff_7_mean: 2.25\n",
      "mean_14: 1.68\n",
      "max_14: 1.26\n",
      "mean_7: 1.12\n",
      "std_7: 1.06\n",
      "std_14: 1.05\n",
      "mean_7_decay: 0.93\n",
      "max_3: 0.77\n",
      "diff_140_mean: 0.70\n",
      "diff_30_mean: 0.70\n",
      "diff_14_mean: 0.56\n",
      "std_3: 0.54\n",
      "mean_3: 0.18\n",
      "diff_3_mean: 0.18\n",
      "diff_60_mean: 0.04\n",
      "median_3: 0.00\n",
      "min_3: 0.00\n",
      "median_7: 0.00\n",
      "min_7: 0.00\n",
      "median_14: 0.00\n",
      "min_14: 0.00\n",
      "median_30: 0.00\n",
      "min_30: 0.00\n",
      "median_60: 0.00\n",
      "min_60: 0.00\n",
      "median_140: 0.00\n",
      "min_140: 0.00\n",
      "==================================================\n",
      "Step 3\n",
      "==================================================\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.0086067\tvalid_1's l2: 0.00857665\n",
      "[100]\ttraining's l2: 0.00856997\tvalid_1's l2: 0.00857965\n",
      "[150]\ttraining's l2: 0.00853846\tvalid_1's l2: 0.0085832\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's l2: 0.00862009\tvalid_1's l2: 0.00857613\n",
      "max_140: 47.03\n",
      "item_nbr: 37.50\n",
      "class: 34.38\n",
      "mean_140: 26.63\n",
      "std_140: 22.91\n",
      "mean_140_decay: 22.71\n",
      "store_nbr: 21.25\n",
      "cluster: 13.90\n",
      "family: 13.11\n",
      "city: 10.96\n",
      "max_60: 10.73\n",
      "mean_60: 10.28\n",
      "mean_60_decay: 9.53\n",
      "std_60: 7.88\n",
      "mean_14_decay: 7.83\n",
      "type: 6.09\n",
      "state: 5.81\n",
      "mean_30_decay: 5.24\n",
      "std_14: 3.49\n",
      "mean_30: 3.27\n",
      "max_14: 2.74\n",
      "diff_14_mean: 2.54\n",
      "perishable: 2.45\n",
      "max_30: 2.37\n",
      "diff_3_mean: 2.04\n",
      "std_30: 2.00\n",
      "mean_14: 1.96\n",
      "diff_140_mean: 1.50\n",
      "mean_7_decay: 1.28\n",
      "max_7: 0.83\n",
      "mean_7: 0.69\n",
      "mean_3_decay: 0.53\n",
      "diff_60_mean: 0.40\n",
      "diff_7_mean: 0.39\n",
      "std_7: 0.33\n",
      "mean_3: 0.15\n",
      "diff_30_mean: 0.10\n",
      "max_3: 0.08\n",
      "median_3: 0.00\n",
      "min_3: 0.00\n",
      "std_3: 0.00\n",
      "median_7: 0.00\n",
      "min_7: 0.00\n",
      "median_14: 0.00\n",
      "min_14: 0.00\n",
      "median_30: 0.00\n",
      "min_30: 0.00\n",
      "median_60: 0.00\n",
      "min_60: 0.00\n",
      "median_140: 0.00\n",
      "min_140: 0.00\n",
      "==================================================\n",
      "Step 4\n",
      "==================================================\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.0104868\tvalid_1's l2: 0.0102385\n",
      "[100]\ttraining's l2: 0.0104454\tvalid_1's l2: 0.01024\n",
      "[150]\ttraining's l2: 0.0104084\tvalid_1's l2: 0.0102445\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's l2: 0.0104748\tvalid_1's l2: 0.0102381\n",
      "item_nbr: 85.44\n",
      "max_140: 82.08\n",
      "class: 65.22\n",
      "std_140: 49.10\n",
      "mean_140_decay: 46.26\n",
      "mean_140: 42.77\n",
      "store_nbr: 42.68\n",
      "family: 26.00\n",
      "cluster: 21.80\n",
      "mean_60_decay: 19.57\n",
      "std_60: 18.90\n",
      "type: 17.41\n",
      "city: 16.94\n",
      "mean_60: 16.32\n",
      "state: 13.68\n",
      "max_60: 13.61\n",
      "mean_30_decay: 11.09\n",
      "mean_30: 9.21\n",
      "max_30: 7.10\n",
      "std_30: 6.16\n",
      "perishable: 5.46\n",
      "mean_14_decay: 4.93\n",
      "mean_14: 2.87\n",
      "max_7: 2.38\n",
      "diff_14_mean: 2.10\n",
      "mean_7_decay: 2.05\n",
      "std_3: 1.95\n",
      "max_14: 1.88\n",
      "diff_60_mean: 1.84\n",
      "diff_7_mean: 1.53\n",
      "diff_30_mean: 1.43\n",
      "std_14: 1.07\n",
      "mean_3: 1.00\n",
      "max_3: 0.87\n",
      "std_7: 0.75\n",
      "mean_7: 0.74\n",
      "mean_3_decay: 0.60\n",
      "diff_140_mean: 0.50\n",
      "diff_3_mean: 0.12\n",
      "median_3: 0.00\n",
      "min_3: 0.00\n",
      "median_7: 0.00\n",
      "min_7: 0.00\n",
      "median_14: 0.00\n",
      "min_14: 0.00\n",
      "median_30: 0.00\n",
      "min_30: 0.00\n",
      "median_60: 0.00\n",
      "min_60: 0.00\n",
      "median_140: 0.00\n",
      "min_140: 0.00\n",
      "==================================================\n",
      "Step 5\n",
      "==================================================\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.0102465\tvalid_1's l2: 0.0103119\n",
      "[100]\ttraining's l2: 0.0102051\tvalid_1's l2: 0.0103143\n",
      "[150]\ttraining's l2: 0.0101702\tvalid_1's l2: 0.0103175\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's l2: 0.0102475\tvalid_1's l2: 0.0103118\n",
      "item_nbr: 73.01\n",
      "max_140: 58.55\n",
      "class: 52.87\n",
      "mean_140_decay: 50.57\n",
      "std_140: 34.08\n",
      "store_nbr: 31.79\n",
      "mean_140: 29.72\n",
      "cluster: 24.19\n",
      "family: 19.56\n",
      "city: 16.35\n",
      "max_60: 15.82\n",
      "mean_60: 13.38\n",
      "std_60: 11.81\n",
      "type: 11.80\n",
      "mean_60_decay: 10.30\n",
      "state: 9.82\n",
      "max_30: 6.22\n",
      "std_30: 6.09\n",
      "mean_30: 5.97\n",
      "mean_3_decay: 5.45\n",
      "perishable: 4.53\n",
      "mean_30_decay: 4.41\n",
      "mean_14_decay: 3.46\n",
      "diff_140_mean: 3.15\n",
      "max_7: 3.03\n",
      "diff_60_mean: 2.70\n",
      "mean_7_decay: 2.22\n",
      "std_14: 2.02\n",
      "max_14: 1.84\n",
      "mean_14: 1.70\n",
      "diff_14_mean: 1.52\n",
      "diff_30_mean: 1.10\n",
      "mean_7: 0.89\n",
      "diff_3_mean: 0.62\n",
      "diff_7_mean: 0.39\n",
      "mean_3: 0.34\n",
      "max_3: 0.29\n",
      "std_3: 0.13\n",
      "median_3: 0.00\n",
      "min_3: 0.00\n",
      "median_7: 0.00\n",
      "min_7: 0.00\n",
      "std_7: 0.00\n",
      "median_14: 0.00\n",
      "min_14: 0.00\n",
      "median_30: 0.00\n",
      "min_30: 0.00\n",
      "median_60: 0.00\n",
      "min_60: 0.00\n",
      "median_140: 0.00\n",
      "min_140: 0.00\n",
      "==================================================\n",
      "Step 6\n",
      "==================================================\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.00848184\tvalid_1's l2: 0.00913959\n",
      "[100]\ttraining's l2: 0.00844793\tvalid_1's l2: 0.00914014\n",
      "[150]\ttraining's l2: 0.00841931\tvalid_1's l2: 0.00914195\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's l2: 0.00846983\tvalid_1's l2: 0.00913917\n",
      "item_nbr: 79.89\n",
      "max_140: 58.59\n",
      "mean_140_decay: 58.52\n",
      "class: 51.62\n",
      "store_nbr: 38.90\n",
      "mean_140: 36.70\n",
      "std_140: 36.20\n",
      "cluster: 25.98\n",
      "family: 19.32\n",
      "city: 18.10\n",
      "mean_60_decay: 15.07\n",
      "std_60: 13.98\n",
      "max_60: 13.92\n",
      "mean_60: 13.36\n",
      "type: 12.53\n",
      "state: 11.04\n",
      "mean_30_decay: 7.13\n",
      "perishable: 5.99\n",
      "max_30: 5.53\n",
      "mean_30: 4.50\n",
      "std_30: 3.15\n",
      "mean_14_decay: 2.87\n",
      "max_7: 2.20\n",
      "mean_14: 2.16\n",
      "std_14: 2.06\n",
      "mean_7: 1.71\n",
      "max_14: 1.45\n",
      "diff_7_mean: 1.24\n",
      "mean_7_decay: 0.99\n",
      "diff_60_mean: 0.99\n",
      "diff_3_mean: 0.98\n",
      "std_7: 0.75\n",
      "diff_30_mean: 0.53\n",
      "mean_3_decay: 0.46\n",
      "diff_140_mean: 0.45\n",
      "diff_14_mean: 0.39\n",
      "mean_3: 0.28\n",
      "std_3: 0.12\n",
      "max_3: 0.07\n",
      "median_3: 0.00\n",
      "min_3: 0.00\n",
      "median_7: 0.00\n",
      "min_7: 0.00\n",
      "median_14: 0.00\n",
      "min_14: 0.00\n",
      "median_30: 0.00\n",
      "min_30: 0.00\n",
      "median_60: 0.00\n",
      "min_60: 0.00\n",
      "median_140: 0.00\n",
      "min_140: 0.00\n",
      "==================================================\n",
      "Step 7\n",
      "==================================================\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.00857511\tvalid_1's l2: 0.00989924\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-b4be931efa49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     bst = lgb.train(\n\u001b[1;32m     23\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_ROUNDS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mvalid_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m125\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     )\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sm/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sm/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1974\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1975\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1976\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1977\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1978\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "val_pred = []\n",
    "test_pred = []\n",
    "cate_vars = []\n",
    "\n",
    "for i in range(num_days_preds):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Step %d\" % (i+1))\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    dtrain = lgb.Dataset(\n",
    "        X_train, label=y_train[:, i],\n",
    "        categorical_feature=cate_vars,\n",
    "        weight=pd.concat([items[\"perishable\"]] * num_days) * 0.25 + 1  # items marked as perishable is given a weight of .25; others are 1\n",
    "    )\n",
    "    dval = lgb.Dataset(\n",
    "        X_val, label=y_val[:, i],\n",
    "        categorical_feature=cate_vars,\n",
    "        weight=items[\"perishable\"] * 0.25 + 1\n",
    "    )\n",
    "    bst = lgb.train(\n",
    "        params, dtrain, num_boost_round=MAX_ROUNDS,\n",
    "        valid_sets=[dtrain, dval], early_stopping_rounds=125, verbose_eval=50\n",
    "    )\n",
    "    \n",
    "    # Interesting trick!\n",
    "    print(\"\\n\".join((\"%s: %.2f\" % x) for x in sorted(\n",
    "        zip(X_train.columns, bst.feature_importance(\"gain\")),\n",
    "        key=lambda x: x[1], reverse=True\n",
    "    )))\n",
    "    \n",
    "    val_pred.append(\n",
    "        bst.predict(X_val, \n",
    "                    num_iteration=bst.best_iteration or MAX_ROUNDS)\n",
    "    )\n",
    "    test_pred.append(\n",
    "        bst.predict(X_test, \n",
    "                    num_iteration=bst.best_iteration or MAX_ROUNDS)\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"\\nValidation mse:\", \n",
    "      mean_squared_error(y_val, np.array(val_pred).transpose()))\n",
    "weight = items['perishable'] * 0.25 + 1\n",
    "err = (y_val - np.array(val_pred).transpose())**2\n",
    "err = err.sum(axis=1) * weight\n",
    "err = np.sqrt(err.sum() / weight.sum() / 16)\n",
    "print(\"Validation nwrmsle = {}\".format(err))\n",
    "print(f\"Time taken: {(time.time() - start) / 60} mins\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
