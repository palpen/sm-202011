{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Import the data\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Pandas options\n",
    "pd.set_option('display.max_colwidth', 1000, 'display.max_rows', None, 'display.max_columns', None)\n",
    "\n",
    "# Plotting options\n",
    "%matplotlib inline\n",
    "mpl.style.use('ggplot')\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "loans = pd.read_csv('../project_1/accepted_2007_to_2018Q4.csv.gz', compression='gzip', low_memory=True) #read data into pandas\n",
    "\n",
    "loans.info()\n",
    "\n",
    "loans.shape #print rows and columns in loan_status\n",
    "\n",
    "loans.head() #loans dataframe\n",
    "\n",
    "#loans = loans.sample(frac=0.05)\n",
    "\n",
    "loans.shape\n",
    "\n",
    "\n",
    "\n",
    "print(loans.describe())\n",
    "\n",
    " #Response Variable or Target Variable\n",
    "\n",
    "loans['loan_status'].value_counts(dropna=False) #Count of each loan_status\n",
    "\n",
    "loans = loans.loc[loans['loan_status'].isin(['Fully Paid', 'Charged Off'])] #Ignore other loan_status\n",
    "loans['loan_status']\n",
    "\n",
    "loans.shape #after removing other loan_status, remaining rows\n",
    "\n",
    "loans['loan_status'].value_counts(normalize=True, dropna=False) #Count of each loan_status as percentages\n",
    "\n",
    "#Drop features missing more than 30% of data\n",
    "\n",
    "missing_fractions = loans.isnull().mean().sort_values(ascending=False) #calculate % of missing data\n",
    "\n",
    "missing_fractions.head(10) #Top 10 features missing most data\n",
    "\n",
    "plt.figure(figsize=(6,3), dpi=90)\n",
    "missing_fractions.plot.hist(bins=20)\n",
    "plt.title('Histogram of Feature Incompleteness')\n",
    "plt.xlabel('Fraction of data missing')\n",
    "plt.ylabel('Feature count')                                #Histograms representing missing data propotions\n",
    "\n",
    "drop_list = sorted(list(missing_fractions[missing_fractions > 0.3].index))\n",
    "print(drop_list)                                               #Make a list of dropping feature having >40% of missing data\n",
    "\n",
    "len(drop_list) #Calculate how many features will be dropped\n",
    "\n",
    "loans.drop(labels=drop_list, axis=1, inplace=True) #drop features\n",
    "\n",
    "loans.shape #check how many columns left after dropping feature\n",
    "\n",
    "#Loan features needed for Investors\n",
    "\n",
    "print(sorted(loans.columns)) #print all the features\n",
    "\n",
    "keep_list = ['addr_state', 'annual_inc', 'application_type', 'dti', 'earliest_cr_line', 'emp_length', 'emp_title', \n",
    "             'fico_range_high', 'fico_range_low', 'grade', 'home_ownership', 'id', 'initial_list_status', 'installment', \n",
    "             'int_rate', 'issue_d', 'loan_amnt', 'loan_status', 'mort_acc', 'open_acc', 'pub_rec', 'pub_rec_bankruptcies',\n",
    "             'purpose', 'revol_bal', 'revol_util', 'sub_grade', 'term', 'title', 'total_acc', 'verification_status',\n",
    "             'zip_code'] #make a list of features useful for  investors\n",
    "\n",
    "len(keep_list) #out of 93 columns we use 31 columns for prediction of loan_status variable\n",
    "\n",
    "drop_list = [col for col in loans.columns if col not in keep_list]\n",
    "print(drop_list)  #drop remaining 62 columns\n",
    "\n",
    "len(drop_list)\n",
    "\n",
    "loans.drop(labels=drop_list, axis=1, inplace=True) #drop drop_list containing list of features not needed\n",
    "\n",
    "loans.shape #columns after dropping features not needed\n",
    "\n",
    "loans.dtypes #checking datatypes of variables in loans dataframe\n",
    "\n",
    "loans.select_dtypes(include=np.object).columns.tolist() #categorical columns in loans dataframe\n",
    "\n",
    "loans.select_dtypes(include=np.float).columns.tolist()\n",
    "\n",
    "#Using Pearson Correlation\n",
    "plt.figure(figsize=(12,10))\n",
    "cor = loans.corr()\n",
    "sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n",
    "plt.show()\n",
    "\n",
    "def plot_var(col_name, full_name, continuous):\n",
    "    \"\"\"\n",
    "    Visualize a variable with and without faceting on the loan status.\n",
    "    - col_name is the variable name in the dataframe\n",
    "    - full_name is the full variable name\n",
    "    - continuous is True if the variable is continuous, False otherwise\n",
    "    \"\"\"\n",
    "    f, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(12,3), dpi=90)\n",
    "    \n",
    "    # Plot without loan status\n",
    "    if continuous:\n",
    "        sns.distplot(loans.loc[loans[col_name].notnull(), col_name], kde=False, ax=ax1)\n",
    "    else:\n",
    "        sns.countplot(loans[col_name], order=sorted(loans[col_name].unique()), color='#5975A4', saturation=1, ax=ax1)\n",
    "    ax1.set_xlabel(full_name)\n",
    "    ax1.set_ylabel('Count')\n",
    "    ax1.set_title(full_name)\n",
    "\n",
    "    # Plot with loan status\n",
    "    if continuous:\n",
    "        sns.boxplot(x=col_name, y='loan_status', data=loans, ax=ax2)\n",
    "        ax2.set_ylabel('')\n",
    "        ax2.set_title(full_name + ' by Loan Status')\n",
    "    else:\n",
    "        charge_off_rates = loans.groupby(col_name)['loan_status'].value_counts(normalize=True).loc[:,'Charged Off']\n",
    "        sns.barplot(x=charge_off_rates.index, y=charge_off_rates.values, color='#5975A4', saturation=1, ax=ax2)\n",
    "        ax2.set_ylabel('Fraction of Loans Charged-off')\n",
    "        ax2.set_title('Charge-off Rate by ' + full_name)\n",
    "    ax2.set_xlabel(full_name)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "#Analyzing categoical data ['id','term','grade','sub_grade','emp_title','emp_length','home_ownership','verification_status',\n",
    "#'issue_d','loan_status','purpose','title', 'zip_code','addr_state', 'earliest_cr_line','initial_list_status',\n",
    "#'application_type']\n",
    "\n",
    "loans['id'].describe() #Usually ID's are unique and independent keys\n",
    "\n",
    "loans.drop('id', axis=1, inplace=True) #drop id\n",
    "\n",
    "\n",
    "\n",
    "loans['term'].value_counts(dropna=False)\n",
    "\n",
    "loans['term'] = loans['term'].apply(lambda s: np.int8(s.split()[0])) #convert them into numericals\n",
    "\n",
    "loans['term'].value_counts(normalize=True)\n",
    "\n",
    "loans.groupby('term')['loan_status'].value_counts(normalize=True).loc[:,'Charged Off']\n",
    "\n",
    "print(sorted(loans['grade'].unique()))\n",
    "\n",
    "print(sorted(loans['sub_grade'].unique()))\n",
    "\n",
    "loans.drop('grade', axis=1, inplace=True) #Drop grade\n",
    "\n",
    "plot_var('sub_grade', 'Subgrade', continuous=False)\n",
    "\n",
    "\n",
    "\n",
    "loans['emp_title'].describe()\n",
    "\n",
    "loans.drop(labels='emp_title', axis=1, inplace=True) #too many unique values\n",
    "\n",
    "\n",
    "\n",
    "loans['emp_length'].value_counts(dropna=False).sort_index()\n",
    "\n",
    "loans['emp_length'].replace('< 1 year', '0 years', inplace=True)\n",
    "\n",
    "loans['emp_length'].replace(to_replace='10+ years', value='10 years', inplace=True)\n",
    "\n",
    "def emp_length_to_int(s):\n",
    "    if pd.isnull(s):\n",
    "        return s\n",
    "    else:\n",
    "        return np.int8(s.split()[0])\n",
    "\n",
    "loans['emp_length'] = loans['emp_length'].apply(emp_length_to_int)\n",
    "\n",
    "loans['emp_length'] = loans['emp_length'].fillna(loans.emp_length.median())\n",
    "\n",
    "loans['emp_length'].value_counts(dropna=False).sort_index()\n",
    "\n",
    "loans.groupby('emp_length')['loan_status'].value_counts(normalize=True).loc[:,'Charged Off']\n",
    "\n",
    "plot_var('emp_length', 'Employment Length', continuous=False)\n",
    "\n",
    "loans.groupby('emp_length')['loan_status'].describe()\n",
    "\n",
    "\n",
    "\n",
    "loans['home_ownership'].value_counts(dropna=False)\n",
    "\n",
    "loans['home_ownership'].replace(['NONE', 'ANY'], 'OTHER', inplace=True)\n",
    "\n",
    "loans['home_ownership'].value_counts(dropna=False)\n",
    "\n",
    "home_ownership_xt = pd.crosstab(loans['home_ownership'], loans['loan_status'])\n",
    "home_ownership_xt\n",
    "\n",
    "# Normalize the cross tab to sum to 1:\n",
    "home_ownership_xt_pct = home_ownership_xt.div(home_ownership_xt.sum(1).astype(float), axis=0)\n",
    "\n",
    "home_ownership_xt_pct.plot(kind='bar', \n",
    "                   stacked=True, \n",
    "                   title='Loan status by Home Ownership')\n",
    "plt.xlabel('Home Ownership')\n",
    "plt.ylabel('Loan Status')\n",
    "\n",
    "plot_var('home_ownership', 'Home Ownership', continuous=False)\n",
    "\n",
    "loans.groupby('home_ownership')['loan_status'].value_counts(normalize=True).loc[:,'Charged Off']\n",
    "\n",
    "\n",
    "\n",
    "loans['verification_status'].value_counts(dropna=False)\n",
    "\n",
    "loans.groupby('verification_status')['loan_status'].value_counts(normalize=True).loc[:,'Charged Off']\n",
    "\n",
    "plot_var('verification_status', 'Verification Status', continuous=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "loans['purpose'].value_counts()\n",
    "\n",
    "loans.groupby('purpose')['loan_status'].value_counts(normalize=True).loc[:,'Charged Off'].sort_values()\n",
    "\n",
    "\n",
    "\n",
    "loans['title'].describe()\n",
    "\n",
    "loans['title'].value_counts().head\n",
    "\n",
    "loans.drop('title', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "loans['zip_code'].describe()\n",
    "\n",
    "loans['addr_state'].sample(5)\n",
    "\n",
    "loans['addr_state'].nunique()\n",
    "\n",
    "loans.drop(labels='zip_code', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "loans['earliest_cr_line'].describe()\n",
    "\n",
    "loans['earliest_cr_line'].isnull().any()\n",
    "\n",
    "\n",
    "\n",
    "loans['initial_list_status'].describe()\n",
    "\n",
    "plot_var('initial_list_status', 'Initial List Status', continuous=False)\n",
    "\n",
    "loans.groupby('initial_list_status')['loan_status'].value_counts(normalize=True).loc[:,'Charged Off']\n",
    "\n",
    "\n",
    "\n",
    "loans['application_type'].value_counts()\n",
    "\n",
    "loans['application_type'].value_counts(normalize=True)\n",
    "\n",
    "loans.groupby('application_type')['loan_status'].value_counts(normalize=True).loc[:,'Charged Off']\n",
    "\n",
    "\n",
    "\n",
    "loans['loan_amnt'].describe()\n",
    "\n",
    "loans['loan_amnt'] = loans['loan_amnt'].apply(lambda x: np.log10(x+1)) #applying log10 to calculate numerical value\n",
    "\n",
    "loans['loan_amnt'].describe()\n",
    "\n",
    "plot_var('loan_amnt', 'Loan Amount', continuous=True)\n",
    "\n",
    "loans.groupby('loan_status')['loan_amnt'].describe()\n",
    "\n",
    "\n",
    "\n",
    "loans['int_rate'].describe()\n",
    "\n",
    "plot_var('int_rate', 'Interest Rate', continuous=True)\n",
    "\n",
    "loans.groupby('loan_status')['int_rate'].describe()\n",
    "\n",
    "loans.groupby('purpose')['int_rate'].describe()\n",
    "\n",
    "loans.groupby('sub_grade')['int_rate'].describe()\n",
    "\n",
    "loans.groupby('sub_grade')['purpose'].describe()\n",
    "\n",
    "\n",
    "\n",
    "loans['installment'].describe()\n",
    "\n",
    "plot_var('installment', 'Installment', continuous=True)\n",
    "\n",
    "loans.groupby('loan_status')['installment'].describe()\n",
    "\n",
    "\n",
    "\n",
    "loans['annual_inc'].describe()\n",
    "\n",
    "loans['log_annual_inc'] = loans['annual_inc'].apply(lambda x: np.log10(x+1))\n",
    "\n",
    "loans.drop('annual_inc', axis=1, inplace=True)\n",
    "\n",
    "loans['log_annual_inc'].describe()\n",
    "\n",
    "plot_var('log_annual_inc', 'Log Annual Income', continuous=True)\n",
    "\n",
    "loans.groupby('loan_status')['log_annual_inc'].describe()\n",
    "\n",
    "\n",
    "\n",
    "loans['dti'].describe()\n",
    "\n",
    "plt.figure(figsize=(8,3), dpi=90)\n",
    "sns.distplot(loans.loc[loans['dti'].notnull() & (loans['dti']<60), 'dti'], kde=False)\n",
    "plt.xlabel('Debt-to-income Ratio')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Debt-to-income Ratio')\n",
    "\n",
    "(loans['dti']>=60).sum()\n",
    "\n",
    "\n",
    "\n",
    "loans.groupby('loan_status')['dti'].describe()\n",
    "\n",
    "\n",
    "\n",
    "loans[['fico_range_low', 'fico_range_high']].describe()\n",
    "\n",
    "loans[['fico_range_low','fico_range_high']].corr()\n",
    "\n",
    "loans['fico_score'] = 0.5*loans['fico_range_low'] + 0.5*loans['fico_range_high']\n",
    "\n",
    "loans.drop(['fico_range_high', 'fico_range_low'], axis=1, inplace=True)\n",
    "\n",
    "plot_var('fico_score', 'FICO Score', continuous=True)\n",
    "\n",
    "loans.groupby('loan_status')['fico_score'].describe()\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,3), dpi=90)\n",
    "sns.countplot(loans['open_acc'], order=sorted(loans['open_acc'].unique()), color='#5975A4', saturation=1)\n",
    "_, _ = plt.xticks(np.arange(0, 90, 5), np.arange(0, 90, 5))\n",
    "plt.title('Number of Open Credit Lines')\n",
    "\n",
    "loans[['open_acc','total_acc']].corr()\n",
    "\n",
    "loans.groupby('loan_status')['open_acc'].describe()\n",
    "\n",
    "\n",
    "\n",
    "loans['pub_rec'].value_counts().sort_index()\n",
    "\n",
    "loans[['pub_rec','pub_rec_bankruptcies']].corr()\n",
    "\n",
    "loans.groupby('loan_status')['pub_rec'].describe()\n",
    "\n",
    "\n",
    "\n",
    "loans['revol_bal'].describe()\n",
    "\n",
    "loans['log_revol_bal'] = loans['revol_bal'].apply(lambda x: np.log10(x+1))\n",
    "\n",
    "loans.drop('revol_bal', axis=1, inplace=True)\n",
    "\n",
    "plot_var('log_revol_bal', 'Log Revolving Credit Balance', continuous=True)\n",
    "\n",
    "loans.groupby('loan_status')['log_revol_bal'].describe()\n",
    "\n",
    "\n",
    "\n",
    "loans['revol_util'].describe()\n",
    "\n",
    "plot_var('revol_util', 'Revolving Line Utilization', continuous=True)\n",
    "\n",
    "loans.groupby('loan_status')['revol_util'].describe()\n",
    "\n",
    "loans[['revol_util','fico_score']].corr()\n",
    "\n",
    "\n",
    "\n",
    "loans.groupby('loan_status')['total_acc'].describe()\n",
    "\n",
    "\n",
    "\n",
    "loans['mort_acc'].describe()\n",
    "\n",
    "loans['mort_acc'].value_counts().head(10)\n",
    "\n",
    "loans.groupby('loan_status')['mort_acc'].describe()\n",
    "\n",
    "\n",
    "\n",
    "loans['pub_rec_bankruptcies'].value_counts().sort_index()\n",
    "\n",
    "plot_var('pub_rec_bankruptcies', 'Public Record Bankruptcies', continuous=False)\n",
    "\n",
    "\n",
    "\n",
    "loans['issue_d'].sample(5)\n",
    "\n",
    "loans['issue_d'].isnull().any()\n",
    "\n",
    "loans['issue_d'] = pd.to_datetime(loans['issue_d'])\n",
    "\n",
    "loans['issue_d'].sample(5)\n",
    "\n",
    "\n",
    "loans['issue_d'].describe()\n",
    "\n",
    "plt.figure(figsize=(6,3), dpi=90)\n",
    "loans['issue_d'].dt.year.value_counts().sort_index().plot.bar(color='darkblue')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Loans Funded')\n",
    "plt.title('Loans Funded per Year')\n",
    "\n",
    "loans['earliest_cr_line'].sample(5)\n",
    "\n",
    "loans['earliest_cr_line'].isnull().any()\n",
    "\n",
    "loans['earliest_cr_line'] = pd.to_datetime(loans['earliest_cr_line'])\n",
    "\n",
    "loans['earliest_cr_line'].sample(5)\n",
    "\n",
    "\n",
    "\n",
    "loans['days_from_issue_to_earliest_cr'] = (loans['issue_d'] - loans['earliest_cr_line']).apply(lambda x: x.days)\n",
    "\n",
    "loans['days_from_issue_to_earliest_cr'].sample(5)\n",
    "\n",
    "loans.groupby('days_from_issue_to_earliest_cr')['loan_status'].value_counts(normalize=True).loc[:,'Charged Off']\n",
    "\n",
    "loans['target'] = (loans['loan_status'] == 'Charged Off').astype(int)\n",
    "loans['target'].describe()\n",
    "\n",
    "_df = loans.groupby('days_from_issue_to_earliest_cr')['target'].mean().reset_index()\n",
    "\n",
    "sns.scatterplot(x='days_from_issue_to_earliest_cr', y='target', data=_df)\n",
    "\n",
    "_df.corr()\n",
    "\n",
    "# Data Analysis\n",
    "\n",
    "* What are you doing?\n",
    "* What have you found?\n",
    "* What action did you take?\n",
    "\n",
    "# Modelling\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "loans.drop('earliest_cr_line', axis=1, inplace=True)\n",
    "\n",
    "loans.drop('days_from_issue_to_earliest_cr', axis=1, inplace=True)\n",
    "\n",
    "loans.drop('target',axis=1,inplace=True)\n",
    "\n",
    "loans['acc_ratio'] = loans['open_acc'] / loans['total_acc']\n",
    "\n",
    "loans.head(4)\n",
    "\n",
    "loans.drop('total_acc', axis=1, inplace=True)\n",
    "\n",
    "loans.drop('open_acc', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "loans.head(20)\n",
    "\n",
    "loans.drop('pub_rec', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "loans['charged_off'] = (loans['loan_status'] == 'Charged Off').apply(np.uint8)\n",
    "loans.drop('loan_status', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "#Using Pearson Correlation\n",
    "plt.figure(figsize=(12,10))\n",
    "cor = loans.corr()\n",
    "sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n",
    "plt.show()\n",
    "\n",
    "loans.shape\n",
    "\n",
    "\n",
    "missing_fractions = loans.isnull().mean().sort_values(ascending=False) # Fraction of data missing for each variable\n",
    "\n",
    "\n",
    "print(missing_fractions[missing_fractions > 0]) # Print variables that are missing data\n",
    "\n",
    "\n",
    "print(loans.columns)\n",
    "\n",
    "loans = pd.get_dummies(loans, columns=['sub_grade', 'home_ownership', 'verification_status', 'purpose', 'addr_state', 'initial_list_status','application_type'], drop_first=True)\n",
    "\n",
    "\n",
    "\n",
    "loans.shape\n",
    "\n",
    "\n",
    "loans.sample(5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6,3), dpi=90)\n",
    "loans['issue_d'].dt.year.value_counts().sort_index().plot.bar(color='darkblue')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Loans Funded')\n",
    "plt.title('Loans Funded per Year')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "loans_train = loans.loc[loans['issue_d'] <  loans['issue_d'].quantile(0.9)]\n",
    "loans_test =  loans.loc[loans['issue_d'] >= loans['issue_d'].quantile(0.9)]\n",
    "\n",
    "print('Number of loans in the partition:   ', loans_train.shape[0] + loans_test.shape[0])\n",
    "print('Number of loans in the full dataset:', loans.shape[0])\n",
    "\n",
    "loans_test.shape[0] / loans.shape[0]\n",
    "\n",
    "del loans\n",
    "\n",
    "loans_train['issue_d'].describe()\n",
    "\n",
    "loans_test['issue_d'].describe()\n",
    "\n",
    "\n",
    "loans_train.drop('issue_d', axis=1, inplace=True)\n",
    "loans_test.drop('issue_d', axis=1, inplace=True)\n",
    "\n",
    "y_train = loans_train['charged_off']\n",
    "y_test = loans_test['charged_off']\n",
    "\n",
    "X_train = loans_train.drop('charged_off', axis=1)\n",
    "X_test = loans_test.drop('charged_off', axis=1)\n",
    "\n",
    "del loans_train, loans_test\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipeline_rfc = Pipeline([\n",
    "    ('imputer', SimpleImputer(copy=False)),\n",
    "    ('model', RandomForestClassifier(n_jobs=-1, random_state=1))\n",
    "])\n",
    "\n",
    "param_grid_rfc = {\n",
    "    'model__n_estimators': [50] # The number of randomized trees to build\n",
    "}\n",
    "\n",
    "grid_rfc = GridSearchCV(estimator=pipeline_rfc, param_grid=param_grid_rfc, scoring='roc_auc', n_jobs=1, pre_dispatch=1, cv=5, verbose=1, return_train_score=False)\n",
    "\n",
    "grid_rfc.fit(X_train, y_train)\n",
    "\n",
    "grid_rfc.best_score_\n",
    "\n",
    "np.any(np.isnan(X_train))\n",
    "\n",
    "np.any(np.isnan(y_train))\n",
    "\n",
    "np.all(np.isfinite(X_train))\n",
    "\n",
    "np.all(np.isfinite(y_train))\n",
    "\n",
    "np.any(np.isnan(X_test))\n",
    "\n",
    "np.any(np.isnan(y_test))\n",
    "\n",
    "X_test = X_test.fillna(X_test.mean())\n",
    "\n",
    "X_train = X_train.fillna(X_train.mean())\n",
    "\n",
    "np.where(y_train.values >= np.finfo(np.float64).max)\n",
    "\n",
    "np.all(np.isfinite(X_test))\n",
    "\n",
    "np.all(np.isfinite(y_test))\n",
    "\n",
    "np.where(y_test.values >= np.finfo(np.float64).max)\n",
    "\n",
    "np.where(X_test.values >= np.finfo(np.float64).max)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# See the inital model performance\n",
    "clf = RandomForestClassifier(random_state=10)\n",
    "print('Acc:', cross_val_score(clf, X_train, y_train, \n",
    "                              cv=StratifiedKFold(n_splits=5), \n",
    "                              scoring='accuracy').mean())\n",
    "print('F1:', cross_val_score(clf, X_train, y_train, \n",
    "                             cv=StratifiedKFold(n_splits=5), \n",
    "                             scoring='f1').mean())\n",
    "print('ROC AUC:', cross_val_score(clf, X_train, y_train, \n",
    "                                  cv=StratifiedKFold(n_splits=5), \n",
    "                                  scoring='roc_auc').mean())\n",
    "\n",
    "\n",
    "\n",
    "y_score = rfc.predict_proba(X_test)[:,1]\n",
    "roc_auc_score(y_test, y_score)\n",
    "\n",
    "from sklearn import model_selection\n",
    "# random forest model creation\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train,y_train)\n",
    "# predictions\n",
    "rfc_predict = rfc.predict(X_test)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "rfc_cv_score =cross_val_score(rfc, X_train, y_train, cv=10, scoring='roc_auc')\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())\n",
    "\n",
    "\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "y_pred_proba = rfc.predict_proba(X_test)[:,1]\n",
    "fpr,tpr,thresholds = roc_curve(y_test,y_pred_proba)\n",
    "\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "roc_auc_score(y_test,y_pred_proba)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure(figsize = (10,8))\n",
    "plt.plot([0, 1], [0.5, 0.5],'k--')\n",
    "plt.plot(recall, precision,'b', label = 'Precision Recall Curve = %0.2f' % auc_prc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('PRC curve')\n",
    "plt.show()\n",
    "\n",
    "# calculate precision-recall AUC\n",
    "auc_prc = auc(recall, precision)\n",
    "print(auc_prc)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
